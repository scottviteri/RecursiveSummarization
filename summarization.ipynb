{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate how to use OpenAI's language model to recursively summarize text from an arbitrary URL. We will use Python and the following libraries: torch, openai, requests, and beautifulsoup4. The code will be explained with comments and markdown explanations.\n",
    "\n",
    "First, let's import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import openai\n",
    "from IPython.core.display import display, Markdown\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"INSERT YOUR API KEY HERE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function chat_query to interact with the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_query(model, query, print_response=True):\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if print_response:\n",
    "        display(Markdown(resp['choices'][0]['message']['content']))\n",
    "    return resp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function model_context_window to get the context window size for the given model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_context_window(model_name):\n",
    "    model_windows = {\n",
    "        \"gpt-3.5-turbo\": 4096,\n",
    "        \"text-davinci-002\": 2048,\n",
    "        # Add other models here\n",
    "    }\n",
    "    return model_windows.get(model_name, 2048)  # Default to 2048 if model not found"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function tokens_to_char to convert tokens to characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_char(tokens): return tokens * 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the main function recursive_summarization that recursively summarizes the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_summarization(model, text, summary_length=1000, last_run=False):\n",
    "    if len(text) <= summary_length and not(last_run):\n",
    "        return recursive_summarization(model, text, summary_length, last_run=True)\n",
    "    print(f\"current length: {len(text)}\")\n",
    "    \n",
    "    context_window = model_context_window(model)\n",
    "    truncation_length = tokens_to_char(context_window) - 2 * summary_length\n",
    "    \n",
    "    summary_query = f\"Please summarize the following text in {summary_length} characters or less: {text[:truncation_length]}\"\n",
    "    summary_response = chat_query(model, summary_query, print_response=False)\n",
    "    summary = summary_response['choices'][0]['message']['content'].strip()\n",
    "    \n",
    "    print(\"num chars in summary: \", len(summary))\n",
    "    remaining_text = text[truncation_length:]\n",
    "    if last_run:\n",
    "        return summary + \" \" + remaining_text\n",
    "    return recursive_summarization(model, summary + \" \" + remaining_text, summary_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function extract_text_from_url to extract text from a given URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = ' '.join([p.text for p in soup.find_all('p')])\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the extract_text_from_url function to get the original text, and then call recursive_summarization to generate the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current length: 84270\n",
      "num chars in summary:  673\n",
      "current length: 72560\n",
      "num chars in summary:  724\n",
      "current length: 60901\n",
      "num chars in summary:  655\n",
      "current length: 49173\n",
      "num chars in summary:  636\n",
      "current length: 37426\n",
      "num chars in summary:  694\n",
      "current length: 25737\n",
      "num chars in summary:  638\n",
      "current length: 13992\n",
      "num chars in summary:  813\n",
      "current length: 2422\n",
      "num chars in summary:  875\n",
      "current length: 876\n",
      "num chars in summary:  687\n",
      "Summary: Midjourney is a beta AI-powered app that generates images based on text prompts with various settings, such as resolution, aspect ratio, and styling options. It offers control and possibilities for users to experiment with their image creations, including lens type, lighting, realism level, and filters. Users can also discard unwanted subjects via the \"--no\" keyword and increase or decrease abstraction with the \"--chaos\" setting. Other AI-based writing tools, such as Smart Copy, ChatGPT-4, ParagraphAI, and Neuroflash, can also help users with copywriting, writing enhancement, and text generation. Additionally, Trenzle is a platform to discover the latest people, work, and ideas. \n"
     ]
    }
   ],
   "source": [
    "original_text = extract_text_from_url(\"https://www.trenzle.com/a-midjourney-ai-complete-guide-how-to-use-cheatsheet-prompts-with-examples-for-beginners/\")\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "summary_length = 2000\n",
    "summary = recursive_summarization(model_name, original_text, summary_length=summary_length)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
